{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " # Projeto Programação e Algoritmia"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Indice\n",
    "1.  Introdução\n",
    "2.  Objetivos\n",
    "3.  Metodologia\n",
    "4.  Dados e pre-processamento\n",
    "5.  Processamento, analise e discussão dos resultados\n",
    "6. Desenvolvimento de um sistema de recomendação de receitas por meio de ML\n",
    "7.  Conclusão e notas finais\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Introdução\n",
    "\n",
    "....\n",
    "\n",
    "Dieta EAT-Lancet é uma dieta que visa disponibilizar o nivel de nutrição adequado para um ser humano medio.\n",
    ".....\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Objetivos\n",
    "O seguinte trabalho visa estudar a composição alimentar de dietas de certos paises, compara-la ao modelo de dieta EAT-Lancet e a composição nutricional de uma lista de receitas do site Food.com, assim como, baseando-se nestes dados, desenvolver um sistema de aprendizagem de maquina capaz de recomendar receitas saudaveis. E para esse fim, sera imprescindivel responder as seguintes questões:\n",
    "\n",
    "\n",
    "1 - Qual a composição duma dieta me portugal, e em egito, EUA , china e Brasil, e quao diferentes estes sao entre si e entre a EAT-Lancet\n",
    "\n",
    "2 - Qual a composição de produtos animais nas dietas dos paises citados e a EAT-Lancet?\n",
    "\n",
    "3 - como se viu a evolução da composição das dietas dos paises citados ao longo dos anos\n",
    "\n",
    "4 - Existe alguma relação entre a avaliação duma receita e o tamanho das avalições? e o numero de estapas? e o numero de ingridientes? e o tempo de demora?\n",
    "\n",
    "5 - como se distribuem as receitas filtradas por EAT-Lancet por categoria? Qual categoria possui melhores avaliações?\n",
    "\n",
    "\n",
    "    perguntas extra ( não tenho certeza se irei incluir ao longo do trabalho):\n",
    "6 - Quais os produtos mais consumidos em paises e qual a relação com a coltura do pais?\n",
    "7 - existe alguma diferença notavel de  proporção entre ingredientes de origem animal e os de origem nao animal?\n",
    "8 - o tempo de preparação da receita influencia de alguma forma o nivel nucticional da receita?\n",
    "9 - como varia a pegada de carbono das dietas dos diferentes paises ao longo do tempo?"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Metodologia\n",
    "\n",
    "Tecnologias usadas na elaboração deste trabalho:\n",
    "    Linguagens de programação: Python;\n",
    "        Bibliotecas: Seaborn, Matplotlib, numpy, plotly, warning, pandas, sklearn...\n",
    "        Classes: \n",
    "    Softwares: Jupyter (atraves de uma extensão do visual studio code);\n",
    "    Formatos de ficheiro de dados: csv,parquet(ou feather) e excel (xls);\n",
    "    Plataforma de hospedagem : github\n",
    "\n",
    "\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Dados e pre-processamento\n",
    "Como ao longo do trabalho sera necessario comunicar dados entre ficheiros e certas informações ou são irrelevantes ou repetidas, irei tratar de preparar os data frames principais para cada pergunta nesta secssão, assim otimiza-se o processamento em si que vem a seguir e evita-se cria um grande dataframe com dados desnecessarios.\n",
    "\n",
    "esta secssao tera 3 partes:\n",
    "1. Preparação do ambiente de trabalho\n",
    "2. leitura e armazenamento dos dados, otimização e adequação dos tipos de dados  (com uma pre-filtragem)\n",
    "4. Filtragem\n",
    "\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###  Preparação do ambiente de trabalho"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 311,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import chart_studio \n",
    "import chart_studio.plotly as py\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import plotly as ply\n",
    "import plotly.express  as px\n",
    "pd.options.plotting.backend = 'plotly'\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "chart_studio.tools.set_credentials_file(username='Mohaamedl', api_key='MvUpzt7O9SQLxrTEuefC')\n",
    "\n",
    "\n",
    "\n",
    "# paths dos ficheiros\n",
    "# filename_diet_animal = '../data/eat-lancet-diet-animal-products.csv' desnecessario visto q esses dados estão ja noutro ficheiro\n",
    "filename_diet_composition = '../data/eat-lancet-diet-comparison (2).csv'\n",
    "filename_food_emission = '../data/food-emissions-supply-chain (1).csv'\n",
    "filename_recipes_raw = 'C:/Users/moham/Documents/data_compressed/RAW_recipes.csv' #! Atenção, deve alterar o caminho para \"../data/nome do ficheiro\" , usei ficheiros no pc pq nao cabem no github, mas estarei a inclui-los no envio final\n",
    "filename_reviews_raw= 'C:/Users/moham/Documents/data_compressed/RAW_interactions.csv'\n",
    "\n",
    "# funções \n",
    "def read_diet_and_emission(filename,cols_not_use=[]):\n",
    "    cols = list(pd.read_csv(filename,nrows=1))\n",
    "    df = pd.read_csv(filename,usecols=list(col for col in cols if  col not in cols_not_use),dtype={'Entity':'category','Code':'category','Year':'int16'})\n",
    "    df['Total'] = df.sum(axis=1)\n",
    "    # reduzir o numero de bits dos float\n",
    "    datatypes = dict.fromkeys(df.select_dtypes(np.float64).columns, np.float16) \n",
    "    df = df.astype(datatypes)\n",
    "    \n",
    "    df2 = pd.read_csv(filename) # descomentar para saber quao otimizado ficou\n",
    "    print(f' De {df2.memory_usage().sum()/1000} Kbytes para {df.memory_usage().sum()/1000} Kbytes, uma redução de {(df2.memory_usage().sum()/1000)/(df.memory_usage().sum()/1000)*100:.2f} % ')\n",
    "    return df\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 314,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " De 88.324 Kbytes para 30.486 Kbytes, uma redução de 289.72 % \n",
      " De 3.916 Kbytes para 1.293 Kbytes, uma redução de 302.86 % \n",
      "          País Code   Ano  cereais  raízes_tubérculos  legumes    frutos  \\\n",
      "0  Afghanistan  AFG  2014   487.50          18.109375  116.875   91.8750   \n",
      "1  Afghanistan  AFG  2015   478.75          17.453125  115.875  104.0000   \n",
      "2  Afghanistan  AFG  2016   480.75          17.562500  198.000   84.9375   \n",
      "3  Afghanistan  AFG  2017   485.75          17.234375  132.500  104.7500   \n",
      "4      Albania  ALB  2014   413.00         122.750000  699.500  444.2500   \n",
      "\n",
      "   lacticínios  carne_vermelha       aves       ovos    marisco  leguminosas  \\\n",
      "0      176.375       22.734375   5.425781   4.054688   0.520508     5.781250   \n",
      "1      157.500       21.265625   5.234375   3.644531   0.575195     6.273438   \n",
      "2      154.000       19.375000   4.574219   3.644531   0.630371     6.546875   \n",
      "3      148.500       18.515625   4.191406   4.109375   0.685059     5.781250   \n",
      "4      930.000      102.812500  37.781250  38.281250  14.632812    16.109375   \n",
      "\n",
      "   frutos_de_casca_rija      óleos     açúcar   Total  \n",
      "0              2.548828  14.523438  23.343750  2984.0  \n",
      "1              1.835938  13.945312  23.671875  2964.0  \n",
      "2              2.437500  15.093750  26.500000  3030.0  \n",
      "3              1.506836  14.328125  24.984375  2980.0  \n",
      "4              9.476562  29.609375  54.218750  4928.0   \n",
      "             Alimento  utilização_do_solo  exploração_agrícola  \\\n",
      "0             Apples           -0.028946             0.225830   \n",
      "1            Bananas           -0.025528             0.269531   \n",
      "2             Barley            0.008675             0.176392   \n",
      "3   Beef (beef herd)           23.234375            56.218750   \n",
      "4  Beef (dairy herd)            1.265625            21.921875   \n",
      "\n",
      "   alimentação_animal  processamento  transporte   varejo   embalagem  \\\n",
      "0            0.000000       0.003820    0.095825  0.016571   0.044525   \n",
      "1            0.000000       0.060150    0.295898  0.020981   0.065674   \n",
      "2            0.000000       0.127686    0.035339  0.263672   0.496826   \n",
      "3            2.681641       1.811523    0.494141  0.233521   0.352051   \n",
      "4            3.503906       1.547852    0.592285  0.254150   0.374512   \n",
      "\n",
      "      perdas      Total  \n",
      "0   0.070801   0.428467  \n",
      "1   0.175171   0.861816  \n",
      "2   0.070679   1.178711  \n",
      "3  14.437500  99.500000  \n",
      "4   3.847656  33.312500  \n"
     ]
    }
   ],
   "source": [
    "df_diet = read_diet_and_emission(filename_diet_composition)\n",
    "\n",
    "df_food_emiss = read_diet_and_emission(filename_food_emission,['Code','Year'])\n",
    "\n",
    "df_diet.columns = [\"País\",'Code', \"Ano\", \"cereais\", \"raízes_tubérculos\", \"legumes\", \"frutos\", \"lacticínios\",\n",
    "            \"carne_vermelha\", \"aves\", \"ovos\", \"marisco\", \"leguminosas\", \"frutos_de_casca_rija\", \"óleos\", \"açúcar\",'Total']\n",
    "\n",
    "df_food_emiss.columns = ['Alimento' , 'utilização_do_solo','exploração_agrícola' ,'alimentação_animal' ,\n",
    "                'processamento','transporte', 'varejo ','embalagem', 'perdas' ,'Total']\n",
    "print(df_diet.head(),'\\n\\n',df_food_emiss.head())"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### leitura e armazenamento dos dados (com uma pre-filtragem)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 251,
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "read_csv() got an unexpected keyword argument 'cols'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[251], line 7\u001b[0m\n\u001b[0;32m      3\u001b[0m cols_diet_all \u001b[39m=\u001b[39m   [\u001b[39m\"\u001b[39m\u001b[39mPaís\u001b[39m\u001b[39m\"\u001b[39m,\u001b[39m'\u001b[39m\u001b[39mCode\u001b[39m\u001b[39m'\u001b[39m, \u001b[39m\"\u001b[39m\u001b[39mAno\u001b[39m\u001b[39m\"\u001b[39m, \u001b[39m\"\u001b[39m\u001b[39mcereais\u001b[39m\u001b[39m\"\u001b[39m, \u001b[39m\"\u001b[39m\u001b[39mraízes_tubérculos\u001b[39m\u001b[39m\"\u001b[39m, \u001b[39m\"\u001b[39m\u001b[39mlegumes\u001b[39m\u001b[39m\"\u001b[39m, \u001b[39m\"\u001b[39m\u001b[39mfrutos\u001b[39m\u001b[39m\"\u001b[39m, \u001b[39m\"\u001b[39m\u001b[39mlacticínios\u001b[39m\u001b[39m\"\u001b[39m,\n\u001b[0;32m      4\u001b[0m                    \u001b[39m\"\u001b[39m\u001b[39mcarne_vermelha\u001b[39m\u001b[39m\"\u001b[39m, \u001b[39m\"\u001b[39m\u001b[39maves\u001b[39m\u001b[39m\"\u001b[39m, \u001b[39m\"\u001b[39m\u001b[39movos\u001b[39m\u001b[39m\"\u001b[39m, \u001b[39m\"\u001b[39m\u001b[39mmarisco\u001b[39m\u001b[39m\"\u001b[39m, \u001b[39m\"\u001b[39m\u001b[39mleguminosas\u001b[39m\u001b[39m\"\u001b[39m, \u001b[39m\"\u001b[39m\u001b[39mfrutos_de_casca_rija\u001b[39m\u001b[39m\"\u001b[39m, \u001b[39m\"\u001b[39m\u001b[39móleos\u001b[39m\u001b[39m\"\u001b[39m, \u001b[39m\"\u001b[39m\u001b[39maçúcar\u001b[39m\u001b[39m\"\u001b[39m]\n\u001b[0;32m      5\u001b[0m cols_diet_ani \u001b[39m=\u001b[39m  [\u001b[39m\"\u001b[39m\u001b[39mPaís\u001b[39m\u001b[39m\"\u001b[39m, \u001b[39m\"\u001b[39m\u001b[39mAno\u001b[39m\u001b[39m\"\u001b[39m, \u001b[39m\"\u001b[39m\u001b[39mlacticínios\u001b[39m\u001b[39m\"\u001b[39m,\n\u001b[0;32m      6\u001b[0m                    \u001b[39m\"\u001b[39m\u001b[39mcarne_vermelha\u001b[39m\u001b[39m\"\u001b[39m, \u001b[39m\"\u001b[39m\u001b[39maves\u001b[39m\u001b[39m\"\u001b[39m, \u001b[39m\"\u001b[39m\u001b[39movos\u001b[39m\u001b[39m\"\u001b[39m, \u001b[39m\"\u001b[39m\u001b[39mmarisco\u001b[39m\u001b[39m\"\u001b[39m]\n\u001b[1;32m----> 7\u001b[0m df_diet \u001b[39m=\u001b[39m pd\u001b[39m.\u001b[39;49mread_csv(filename_diet_composition,usecols\u001b[39m=\u001b[39;49m\u001b[39mlist\u001b[39;49m(col \u001b[39mfor\u001b[39;49;00m col \u001b[39min\u001b[39;49;00m cols \u001b[39mif\u001b[39;49;00m  col \u001b[39mnot\u001b[39;49;00m \u001b[39min\u001b[39;49;00m []),cols\u001b[39m=\u001b[39;49mcols_diet_all) \u001b[39m# code neste caso nao interessa\u001b[39;00m\n\u001b[0;32m      8\u001b[0m df_diet\n\u001b[0;32m      9\u001b[0m \u001b[39m\"\"\" \u001b[39;00m\n\u001b[0;32m     10\u001b[0m \u001b[39mdf_test.columns = cols_diet_all\u001b[39;00m\n\u001b[0;32m     11\u001b[0m \n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m     54\u001b[0m \u001b[39mfigs.show()\u001b[39;00m\n\u001b[0;32m     55\u001b[0m \u001b[39mdf1 \"\"\"\u001b[39;00m\n",
      "File \u001b[1;32m~\\AppData\\Roaming\\Python\\Python311\\site-packages\\pandas\\util\\_decorators.py:211\u001b[0m, in \u001b[0;36mdeprecate_kwarg.<locals>._deprecate_kwarg.<locals>.wrapper\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m    209\u001b[0m     \u001b[39melse\u001b[39;00m:\n\u001b[0;32m    210\u001b[0m         kwargs[new_arg_name] \u001b[39m=\u001b[39m new_arg_value\n\u001b[1;32m--> 211\u001b[0m \u001b[39mreturn\u001b[39;00m func(\u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n",
      "File \u001b[1;32m~\\AppData\\Roaming\\Python\\Python311\\site-packages\\pandas\\util\\_decorators.py:331\u001b[0m, in \u001b[0;36mdeprecate_nonkeyword_arguments.<locals>.decorate.<locals>.wrapper\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m    325\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mlen\u001b[39m(args) \u001b[39m>\u001b[39m num_allow_args:\n\u001b[0;32m    326\u001b[0m     warnings\u001b[39m.\u001b[39mwarn(\n\u001b[0;32m    327\u001b[0m         msg\u001b[39m.\u001b[39mformat(arguments\u001b[39m=\u001b[39m_format_argument_list(allow_args)),\n\u001b[0;32m    328\u001b[0m         \u001b[39mFutureWarning\u001b[39;00m,\n\u001b[0;32m    329\u001b[0m         stacklevel\u001b[39m=\u001b[39mfind_stack_level(),\n\u001b[0;32m    330\u001b[0m     )\n\u001b[1;32m--> 331\u001b[0m \u001b[39mreturn\u001b[39;00m func(\u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n",
      "\u001b[1;31mTypeError\u001b[0m: read_csv() got an unexpected keyword argument 'cols'"
     ]
    }
   ],
   "source": [
    "chart_studio.tools.set_credentials_file(username='Mohaamedl', api_key='MvUpzt7O9SQLxrTEuefC')\n",
    "cols = list(pd.read_csv(filename_diet_composition,nrows=1))\n",
    "cols_diet_all =   [\"País\",'Code', \"Ano\", \"cereais\", \"raízes_tubérculos\", \"legumes\", \"frutos\", \"lacticínios\",\n",
    "                   \"carne_vermelha\", \"aves\", \"ovos\", \"marisco\", \"leguminosas\", \"frutos_de_casca_rija\", \"óleos\", \"açúcar\"]\n",
    "cols_diet_ani =  [\"País\", \"Ano\", \"lacticínios\",\n",
    "                   \"carne_vermelha\", \"aves\", \"ovos\", \"marisco\"]\n",
    "df_diet = pd.read_csv(filename_diet_composition,usecols=list(col for col in cols if  col not in [])) # por na lista o que não interessar\n",
    "df_diet\n",
    "\"\"\" \n",
    "df_test.columns = cols_diet_all\n",
    "\n",
    "print(list(col for col in cols if  col not in ('Code')))\n",
    "\n",
    "\n",
    "\n",
    "def barPlot_diet(df,year,countries=['Portugal']):\n",
    "    df = df[(df['País'].isin(countries) ) & (df['Ano']==year)] # filtrar os dados por ano e paises\n",
    "    \n",
    "    print(df)\n",
    "    df1 = pd.melt(df, \n",
    "        id_vars='País', \n",
    "        value_vars=list(df.columns[3:-1]),\n",
    "        var_name='Tipo', \n",
    "        value_name='Consumo(g)'\n",
    "        ) # converte numa dataframe mais legivel para px, é como um pd.pivot reverso \n",
    "    #plot \n",
    "    fig = px.bar(df1,x='Consumo(g)',\n",
    "                y='País',\n",
    "                color='Tipo',\n",
    "                text='Tipo',\n",
    "                barmode='relative',\n",
    "                title='Composisão de dieta por pais dividida por tipo de alimento'\n",
    "                )\n",
    "    \n",
    "\n",
    "    fig.update_traces(textposition=\"inside\")\n",
    "    fig.update_traces(visible=True, )\n",
    "    return fig\n",
    "\n",
    "countries = ['Portugal','Spain','United States','India','China','Egypt','EAT-Lancet']\n",
    "countries1 = ['Portugal','EAT-Lancet']\n",
    "year = 2017\n",
    "df1= df_test[(df_test['País'].isin(countries))] \n",
    "df1['Soma'] = df1.iloc[:,6:11].sum(axis=1)\n",
    "df_test['Soma'] = df_test.iloc[:,6:11].sum(axis=1)\n",
    "figs = px.scatter_geo(df_test, locations=\"Code\",\n",
    "                        color='País',\n",
    "                        hover_name='País',\n",
    "                        animation_frame='Ano',\n",
    "                        size=\"Soma\",\n",
    "                        projection=\"natural earth\")\n",
    "fig = barPlot_diet(df_test,year,countries)\n",
    "fig.show()\n",
    "figs.show()\n",
    "df1 \"\"\"\n",
    "#py.plot(fig) # para publicar no chart studio\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.2"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
